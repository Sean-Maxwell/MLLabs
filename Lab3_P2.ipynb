{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import*\n",
    "# Useful for matplotlib in JN's\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying any missing attributes only from (MPG, Cylinders, Horsepower and displacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
      "0   18.0          8         307.0         130    3504          12.0   \n",
      "1   15.0          8         350.0         165    3693          11.5   \n",
      "2   18.0          8         318.0         150    3436          11.0   \n",
      "3   16.0          8         304.0         150    3433          12.0   \n",
      "4   17.0          8         302.0         140    3449          10.5   \n",
      "5   15.0          8         429.0         198    4341          10.0   \n",
      "6   14.0          8         454.0         220    4354           9.0   \n",
      "7   14.0          8         440.0         215    4312           8.5   \n",
      "8   14.0          8         455.0         225    4425          10.0   \n",
      "9   15.0          8         390.0         190    3850           8.5   \n",
      "10  15.0          8         383.0         170    3563          10.0   \n",
      "11  14.0         20         340.0         160    3609           8.0   \n",
      "12  15.0          8         400.0         150    3761           9.5   \n",
      "13  14.0          8         455.0         225    3086          10.0   \n",
      "14  24.0          4         113.0          95    2372          15.0   \n",
      "15  22.0          6         198.0          95    2833          15.5   \n",
      "16  18.0          6         199.0          97    2774          15.5   \n",
      "17  21.0          6         200.0          85    2587          16.0   \n",
      "18  27.0          4          97.0          88    2130          14.5   \n",
      "19  26.0          4          97.0          46    1835          20.5   \n",
      "\n",
      "    model year  origin  \n",
      "0           70       1  \n",
      "1           70       1  \n",
      "2           70       1  \n",
      "3           70       1  \n",
      "4           70       1  \n",
      "5           70       1  \n",
      "6           70       1  \n",
      "7           70       1  \n",
      "8           70       1  \n",
      "9           70       1  \n",
      "10          70       1  \n",
      "11          70       1  \n",
      "12          70       1  \n",
      "13          70       1  \n",
      "14          70       3  \n",
      "15          70       1  \n",
      "16          70       1  \n",
      "17          70       1  \n",
      "18          70       3  \n",
      "19          70       2  \n"
     ]
    }
   ],
   "source": [
    "# Useful for matplotlib in JN's\n",
    "%matplotlib inline\n",
    "\n",
    "fileName = r'C:\\Users\\smaxw\\Downloads\\auto-mpg-errors.csv'\n",
    "##Naming the columns in memory\n",
    "namesCol = [\n",
    "'mpg',\n",
    "'cylinders',\n",
    "'displacement',\n",
    "'horsepower',\n",
    "'weight',\n",
    "'acceleration',\n",
    "'model year',\n",
    "'origin'\n",
    "]\n",
    "\n",
    "##Printing the first 20 columns of all the data.\n",
    "data = pd.read_csv(fileName, names=namesCol)\n",
    "print(data.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Getting further information the rows of data i.e. mean, std deviation\n",
    "print(data.describe())\n",
    "print()\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying the missing data in the auto-mpg-erros csv file using print statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Checking that there are no non-numeric values.\n",
    "print((data == 0).sum())\n",
    "print()\n",
    "print((data < 0).sum())\n",
    "print()\n",
    "print(data.std())\n",
    "print()\n",
    "print(data.mean())\n",
    "\n",
    "#Checking specific columns\n",
    "print((data['mpg'] == 0).sum())\n",
    "print()\n",
    "print((data['mpg'] < 0).sum())\n",
    "print()\n",
    "print(data['mpg'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking specific columns\n",
    "print((data['cylinders'] == 0).sum())\n",
    "print()\n",
    "print((data['cylinders'] < 0).sum())\n",
    "print()\n",
    "print(data['cylinders'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking specific columns\n",
    "print((data['displacement'] == 0).sum())\n",
    "print()\n",
    "print((data['displacement'] < 0).sum())\n",
    "print()\n",
    "print(data['displacement'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking specific columns\n",
    "print((data['horsepower'] == 0).sum())\n",
    "print()\n",
    "print((data['horsepower'] < 0).sum())\n",
    "print()\n",
    "print(data['horsepower'].mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Writing a function to identify if any outliers are in the mpg column\n",
    "def plotAttribute(featureName):\n",
    "    oneSTD = data[featureName].std()\n",
    "    twoSTD = oneSTD * 2\n",
    "    threeSTD = oneSTD * 3\n",
    "    meanValue = data[featureName].mean()\n",
    "    print(\"Attribue:\", featureName.upper())\n",
    "    print(\"Summary:\")\n",
    "    instances = data.shape[0]\n",
    "    outsideTwo = ((data[featureName] < (meanValue - twoSTD)).sum() +(data[featureName] > (meanValue + twoSTD)).sum())\n",
    "    outsideThree = ((data[featureName] < (meanValue - threeSTD)).sum() +(data[featureName] > (meanValue + threeSTD)).sum())\n",
    "    print(\"N outside of two STD:\\t\", outsideTwo, \"\\t(\", round((outsideTwo/instances) *100, 2),\"%)\")\n",
    "    print(\"N outside of three STD:\\t\", outsideThree, \"\\t(\", round((outsideThree/instances) * 100, 2),\"%)\")\n",
    "    plt.axvline(x=(meanValue - oneSTD), label='One STD', c=\"g\")\n",
    "    plt.axvline(x=(meanValue + oneSTD), c=\"g\")\n",
    "\n",
    "    plt.axvline(x=(meanValue - twoSTD), label='Two STD', c=\"y\")\n",
    "    plt.axvline(x=(meanValue + twoSTD), c=\"y\")\n",
    "    plt.axvline(x=(meanValue - threeSTD), label='Three STD', c=\"r\")\n",
    "    plt.axvline(x=(meanValue + threeSTD), c=\"r\")\n",
    "    data[featureName].hist(figsize=(7,7))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "for attribute in namesCol:\n",
    "    plotAttribute(attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No missing data to mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##As per instructions I removed \"?\" and entered -1\n",
    "data = pd.read_csv(fileName, names=namesCol)\n",
    "data = data.mask(data == 0, np.NaN)\n",
    "print(data.head(20))\n",
    "\n",
    "data = pd.read_csv(fileName, names=namesCol)\n",
    "data[\"mpg\"] = data[\"mpg\"].mask(data[\"mpg\"] == 0, np.NaN)\n",
    "print(data.head(20))\n",
    "print(\"\\n\\n Missing data:\", data.isnull().sum())\n",
    "\n",
    "data = pd.read_csv(fileName, names=namesCol)\n",
    "data[[\"mpg\", \"cylinders\",\"displacement\",\"horsepower\"]] = data[[\"mpg\", \"cylinders\",\"displacement\",\"horsepower\"]].mask(data[[\"mpg\", \"cylinders\",\"displacement\",\"horsepower\"]] == 0,np.NaN)\n",
    "print(data.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chose whether to remove or Impute data. Complete this process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code for removing any instaces of missing data (no missing data in the csv)\n",
    "data = pd.read_csv(fileName, names=namesCol)\n",
    "print(data.isnull().sum())\n",
    "print()\n",
    "\n",
    "## Find the NaN's and replace with zero.\n",
    "data[\"mpg\"] = data[\"mpg\"].mask(data[\"mpg\"] == 0, np.NaN)\n",
    "print(data.head(20))\n",
    "print()\n",
    "\n",
    "# Counting the null values\n",
    "print(\"Missing Data:\", data.isnull().sum())\n",
    "print(\"\\n\\n\")\n",
    "print(data.shape)\n",
    "\n",
    "#drop rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save the data from memory to a csv file.\n",
    "data.to_csv(r\"C:\\Users\\smaxw\\Downloads\\auto-mpg-cleaned.csv\", header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise or standardise the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data.corr())\n",
    "print()\n",
    "for col in namesCol[:-1]:\n",
    "    print(col,\"\\t\", data[col].corr(data[\"cylinders\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to an array\n",
    "array = data.values\n",
    "X = array[:,0:7]\n",
    "Y = array[:,7]\n",
    "scaler = preprocessing.Normalizer().fit(X)\n",
    "normalizedX = scaler.transform(X)\n",
    "normalizedX = pd.DataFrame(normalizedX)\n",
    "Y = pd.DataFrame(Y)\n",
    "outData = pd.concat([normalizedX, Y], axis=1, sort=False)\n",
    "outData.to_csv(r\"C:\\Users\\smaxw\\Downloads\\auto_mpg_Norm.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Convert to an array\n",
    "array = data.values\n",
    "X = array[:,0:7]\n",
    "Y = array[:,7]\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "normalizedX = scaler.transform(X)\n",
    "normalizedX = pd.DataFrame(normalizedX)\n",
    "Y = pd.DataFrame(Y)\n",
    "outData = pd.concat([normalizedX, Y], axis=1, sort=False)\n",
    "outData.to_csv(r\"C:\\Users\\smaxw\\Downloads\\auto_mpg_Stand.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the top 4 attributes using the following methods: Correlation, Regression, RFE, and Principal Component Analysis. Regression Largest values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mpg            385.51\n",
      "cylinders      104.81\n",
      "displacement     288.78\n",
      "horsepower     247.34\n"
     ]
    }
   ],
   "source": [
    "array = data.values\n",
    "# get seperated input and classifies, using a deep copy of a list\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]\n",
    "\n",
    "test = feature_selection.SelectKBest(score_func=feature_selection.f_regression,k=4)\n",
    "fit = test.fit(X, Y)\n",
    "print()\n",
    "\n",
    "# have to manually display as no function to do so available\n",
    "for index, result in enumerate(fit.scores_):\n",
    "    print(\"{0:10}\".format(namesCol[index]),\"{0:10}\".format(round(result,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Dev\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:68: FutureWarning: Pass n_features_to_select=3 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "C:\\Dev\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 3\n",
      "\n",
      "Attribute  Select?    Rank      \n",
      "---------------------------------\n",
      "mpg        1          1         \n",
      "cylinders  0          2         \n",
      "displacement 1          1         \n",
      "horsepower 1          1         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Dev\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "array = data.values\n",
    "# get seperated input and classifies, using a deep copy of a list\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]\n",
    "model = linear_model.LogisticRegression()\n",
    "rfe = feature_selection.RFE(model, 3)\n",
    "\n",
    "##Calculate RFE\n",
    "fit = rfe.fit(X, Y)\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(\"\\n{0:<10}\".format(\"Attribute\"),\"{0:<10}\".format(\"Select?\"), \"{0:<10}\".format(\"Rank\"))\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "for index, result in enumerate(list(fit.ranking_)):\n",
    "    print(\"{0:<10}\".format(namesCol[index]),\"{0:<10}\".format(fit.support_[index]),\"{0:<10}\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Component 1  explains the following variance : 96.98 %\n",
      "PCA Component 2  explains the following variance : 2.79 %\n",
      "\n",
      "PCA Component 1\n",
      "\tAttribute  PCA       \n",
      "\t-------------------------------------\n",
      "\n",
      "PCA Component 2\n",
      "\tAttribute  PCA       \n",
      "\t-------------------------------------\n",
      "\tmpg        0.028410640068005335\n",
      "\tcylinders  0.010491763103398498\n",
      "\tdisplacement 0.3299661912772182\n",
      "\thorsepower -0.943506794385666\n"
     ]
    }
   ],
   "source": [
    "array = data.values\n",
    "# get seperated input and classifies, using a deep copy of a list\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]\n",
    "noOfPrincipalComponents = 2\n",
    "pca = decomposition.PCA(n_components=noOfPrincipalComponents)\n",
    "fit = pca.fit(X)\n",
    "\n",
    "for component in range(noOfPrincipalComponents):\n",
    "    print(\"PCA Component\",(component + 1), \" explains the following variance :\",round(fit.explained_variance_ratio_[component] *100, 2), \"%\")\n",
    "for component in range(noOfPrincipalComponents):\n",
    "    print(\"\\nPCA Component\",(component + 1))\n",
    "    print(\"\\t{0:<10}\".format(\"Attribute\"), \"{0:<10}\".format(\"PCA\"))\n",
    "    print(\"\\t-------------------------------------\")\n",
    "\n",
    "for index, result in enumerate(fit.components_[component]):\n",
    "    print(\"\\t{0:10}\".format(namesCol[index]), \"{0:10}\".format(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
